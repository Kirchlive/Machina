LLM2LLM-Bridge Documentation
=============================

Willkommen zur offiziellen Dokumentation der **LLM2LLM-Bridge** - einer universellen Middleware fÃ¼r bidirektionale LLM-Kommunikation.

Die LLM2LLM-Bridge ist eine hochperformante, erweiterbare Plattform, die es ermÃ¶glicht, verschiedene Large Language Models nahtlos zu orchestrieren und komplexe Workflows zu automatisieren.

ğŸš€ **Schnellstart**
-------------------

.. code-block:: python

    from llm_bridge.core import LLMBridgeCore
    import asyncio

    async def main():
        # Bridge initialisieren (lÃ¤dt automatisch Plugins und Model Registry)
        bridge = LLMBridgeCore()
        
        # VerfÃ¼gbare Modelle anzeigen
        models = bridge.get_available_models()
        print("VerfÃ¼gbare Modelle:", models)
        
        # Nachricht senden
        response = await bridge.bridge_message(
            conversation_id="demo_chat",
            target_llm_name="claude35_sonnet_via_or",
            message="ErklÃ¤re Quantencomputing in einem Satz."
        )
        print("Antwort:", response)
        
        # Workflow aus YAML-Datei ausfÃ¼hren
        result = await bridge.execute_workflow_from_file("my_workflow.yaml")
        print("Workflow-Ergebnis:", result)

    asyncio.run(main())

ğŸ“– **Inhaltsverzeichnis**
-------------------------

.. toctree::
   :maxdepth: 2
   :caption: Benutzerhandbuch

   quickstart
   installation
   configuration
   workflows

.. toctree::
   :maxdepth: 2
   :caption: API-Referenz

   api/core
   api/routing
   api/plugins
   api/orchestration

.. toctree::
   :maxdepth: 2
   :caption: Entwickler-Guide

   development/plugins
   development/adapters
   development/extending

.. toctree::
   :maxdepth: 1
   :caption: ZusÃ¤tzliches

   changelog
   contributing
   license

âœ¨ **Hauptfeatures**
---------------------

ğŸ”Œ **Plugin-System**
   Dynamisches Laden von LLM-Adaptern basierend auf verfÃ¼gbaren API-SchlÃ¼sseln

ğŸ”„ **Workflow-Engine**
   YAML-basierte Orchestrierung komplexer, mehrstufiger LLM-Pipelines

ğŸ“Š **Observability**
   Integration mit LangFuse fÃ¼r umfassendes Monitoring und Tracing

ğŸ›¡ï¸ **Resilience**
   Circuit Breaker Pattern und State Machines fÃ¼r hohe VerfÃ¼gbarkeit

ğŸŒ **API Gateway**
   RESTful API fÃ¼r einfache Integration in bestehende Systeme

ğŸ“‹ **Model Registry**
   Zentrale Konfiguration und Verwaltung aller unterstÃ¼tzten LLM-Modelle

Indizes und Tabellen
====================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`