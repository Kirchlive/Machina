# In llm_bridge/adapters/openrouter_adapter.py

from .base_adapter import BaseAdapter
from ..utils.http_client import HTTPClientManager
import json

# Der Klassenname wurde hier final ge√§ndert
class OpenRouterAdapter(BaseAdapter):
    """
    Ein universeller Adapter, optimiert f√ºr OpenAI-kompatible APIs wie OpenRouter.
    Er kann jede API ansteuern, die der OpenAI-Spezifikation folgt.
    """
    def __init__(self, api_key: str, base_url: str = None, extra_headers: dict = None):
        """
        Initialisiert den Adapter.

        Args:
            api_key (str): Der API-Schl√ºssel f√ºr den Dienst.
            base_url (str, optional): Die Basis-URL der API. Notwendig f√ºr OpenRouter.
            extra_headers (dict, optional): Zus√§tzliche HTTP-Header (z.B. f√ºr Rankings).
        """
        # Speichere Parameter f√ºr HTTP-Requests
        self.api_key = api_key
        self.base_url = base_url or "https://openrouter.ai/api/v1"
        self.extra_headers = extra_headers or {}
        
        # Basis-Headers f√ºr alle Requests
        self._base_headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            **self.extra_headers
        }

    async def send(self, prompt: str, model: str, **kwargs) -> str:
        """
        Sendet einen Prompt an das spezifizierte Modell √ºber die konfigurierte API.
        Verwendet den zentralen HTTP-Client f√ºr optimales Connection Pooling.

        Args:
            prompt (str): Der Input-Prompt.
            model (str): Das zu verwendende Modell (z.B. "openai/gpt-4o" oder "deepseek-r1:latest").
            **kwargs: Zus√§tzliche API-Parameter (inkl. dynamische base_url).

        Returns:
            str: Die Antwort des LLM.
        """
        if not model:
            return "Error: Ein 'model'-Parameter ist f√ºr den OpenRouterAdapter zwingend erforderlich."
        
        # Dynamische base_url f√ºr Ollama etc.
        # Wenn eine base_url in kwargs √ºbergeben wird, hat diese Vorrang.
        dynamic_base_url = kwargs.pop('base_url', self.base_url)
        endpoint = f"{dynamic_base_url.rstrip('/')}/chat/completions"
        
        # Bereite Request-Payload vor
        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            **kwargs  # Zus√§tzliche Parameter wie temperature, max_tokens, etc.
        }
        
        # Verwende den zentralen HTTP-Client
        client = await HTTPClientManager.get_client()
        
        try:
            print(f"üåê [HTTP] Sending request to {endpoint} with model {model}")
            
            response = await client.post(
                endpoint,
                json=payload,
                headers=self._base_headers
            )
            
            # Pr√ºfe HTTP-Status
            response.raise_for_status()
            
            # Parse JSON Response
            data = response.json()
            
            # Extrahiere Antwort
            if "choices" in data and len(data["choices"]) > 0:
                content = data["choices"][0]["message"]["content"]
                return content.strip() if content else ""
            else:
                raise ValueError(f"Unexpected response format: {data}")
                
        except Exception as e:
            print(f"‚ùå [HTTP] Error in OpenRouterAdapter for model '{model}' at '{endpoint}': {e}")
            # Re-raise f√ºr Circuit Breaker
            raise e